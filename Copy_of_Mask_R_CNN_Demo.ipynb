{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Mask R-CNN Demo",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauabe/video-recognition/blob/dev/Copy_of_Mask_R_CNN_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlmQIFSLZDdc",
        "colab_type": "text"
      },
      "source": [
        "#[How to run Object Detection and Segmentation on a Video Fast for Free](https://www.dlology.com/blog/how-to-run-object-detection-and-segmentation-on-video-fast-for-free/)\n",
        "\n",
        "## Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnAQ-FoO_iTF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IEVK-KFxi5Z",
        "colab_type": "code",
        "outputId": "55c12be1-5b7b-479d-8a20-b6a1231e34ff",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4QlSH4BAmvF",
        "colab_type": "text"
      },
      "source": [
        "## Install pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jkma4_y0Gn8",
        "colab_type": "code",
        "outputId": "73501116-4831-4671-9d65-f080e7db6722",
        "colab": {}
      },
      "source": [
        "!pip install Cython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT7xOQD5pS5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1efXeBhJ0MIi",
        "colab_type": "code",
        "outputId": "958401c6-a4b5-4433-80b5-e487320b6291",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/waleedka/coco"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85CxqaK8yHEV",
        "colab_type": "code",
        "outputId": "0bbff1d7-d817-402c-cd42-f291c1717f17",
        "colab": {}
      },
      "source": [
        "!pip install -U setuptools\n",
        "!pip install -U wheel\n",
        "!make install -C coco/PythonAPI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DswpLud4A0jf",
        "colab_type": "text"
      },
      "source": [
        "## Git Clone the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MrtCPbyzb12",
        "colab_type": "code",
        "outputId": "57dd05f0-52fa-4faa-f0c7-14554e87893c",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZd4msdzA5HT",
        "colab_type": "text"
      },
      "source": [
        "## cd to the code directory and optionally download the weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0-rILHgMR3Dw",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuWUMbul22-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('./Mask_RCNN')\n",
        "!git checkout 555126ee899a144ceff09e90b5b2cf46c321200c\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_bTpx1X9Yjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHLQOznQ-WSC",
        "colab_type": "text"
      },
      "source": [
        "# Mask R-CNN Demo\n",
        "\n",
        "A quick intro to using the pre-trained model to detect and segment objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NInWHdIE2GpR",
        "colab_type": "code",
        "outputId": "eb642ff1-6fb0-4667-92be-1bf69906097a",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import coco\n",
        "import utils\n",
        "import model as modellib\n",
        "import visualize\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04kWKli09fpq",
        "colab_type": "text"
      },
      "source": [
        "## Configurations\n",
        "\n",
        "We'll be using a model trained on the MS-COCO dataset. The configurations of this model are in the ```CocoConfig``` class in ```coco.py```.\n",
        "\n",
        "For inferencing, modify the configurations a bit to fit the task. To do so, sub-class the ```CocoConfig``` class and override the attributes you need to change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rymd_7lP9gCC",
        "colab_type": "code",
        "outputId": "75ce128f-de9d-4858-c9f1-3ab6f9d0c68d",
        "colab": {}
      },
      "source": [
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5PVECAQ9kkn",
        "colab_type": "text"
      },
      "source": [
        "## Create Model and Load Trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3wcuq8-9g7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "\n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alMRDVDo9qGB",
        "colab_type": "text"
      },
      "source": [
        "## Class Names\n",
        "\n",
        "The model classifies objects and returns class IDs, which are integer value that identify each class. Some datasets assign integer values to their classes and some don't. For example, in the MS-COCO dataset, the 'person' class is 1 and 'teddy bear' is 88. The IDs are often sequential, but not always. The COCO dataset, for example, has classes associated with class IDs 70 and 72, but not 71.\n",
        "\n",
        "To improve consistency, and to support training on data from multiple sources at the same time, our ```Dataset``` class assigns it's own sequential integer IDs to each class. For example, if you load the COCO dataset using our ```Dataset``` class, the 'person' class would get class ID = 1 (just like COCO) and the 'teddy bear' class is 78 (different from COCO). Keep that in mind when mapping class IDs to class names.\n",
        "\n",
        "To get the list of class names, you'd load the dataset and then use the ```class_names``` property like this.\n",
        "```\n",
        "# Load COCO dataset\n",
        "dataset = coco.CocoDataset()\n",
        "dataset.load_coco(COCO_DIR, \"train\")\n",
        "dataset.prepare()\n",
        "\n",
        "# Print class names\n",
        "print(dataset.class_names)\n",
        "```\n",
        "\n",
        "We don't want to require you to download the COCO dataset just to run this demo, so we're including the list of class names below. The index of the class name in the list represent its ID (first class is 0, second is 1, third is 2, ...etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4BA4vKD9mbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8IqukPA9vC0",
        "colab_type": "text"
      },
      "source": [
        "## Run Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYCQe9ex9oj3",
        "colab_type": "code",
        "outputId": "8dcdbf28-7d23-4b07-fa04-3767c85346ea",
        "colab": {}
      },
      "source": [
        "# Load a random image from the images folder\n",
        "file_names = next(os.walk(IMAGE_DIR))[2]\n",
        "image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
        "\n",
        "# Run detection\n",
        "results = model.detect([image], verbose=1)\n",
        "\n",
        "# Visualize results\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mrNkY5a9xS3",
        "colab_type": "code",
        "outputId": "ee9ee220-3681-42e1-a926-ca3c549f5abd",
        "colab": {}
      },
      "source": [
        "# Load a random image from the images folder\n",
        "file_names = next(os.walk(IMAGE_DIR))[2]\n",
        "image = skimage.io.imread(os.path.join(IMAGE_DIR, '8734543718_37f6b8bd45_z.jpg'))\n",
        "\n",
        "# Run detection\n",
        "results = model.detect([image], verbose=1)\n",
        "\n",
        "# Visualize results\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRuz2KLuHOMA",
        "colab_type": "text"
      },
      "source": [
        "## Custom image\n",
        "You can upload an image to a third party website like\n",
        "\n",
        "*   [imgbb](https://imgbb.com/)\n",
        "*   [GitHub](https://github.com) repo raw image\n",
        "\n",
        "Then download the image url here with `wget`.\n",
        "\n",
        "We will also introduce using Google drive with Colab in the later section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg47GK_9C4mb",
        "colab_type": "code",
        "outputId": "05b3b632-8373-4d00-b37f-f9b91bc59f26",
        "colab": {}
      },
      "source": [
        "!wget https://ibb.co/56vZBQ5 -P ./images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QowhnmS2EqxU",
        "colab_type": "code",
        "outputId": "d79c94db-2a57-4fd5-8727-b63b994909e4",
        "colab": {}
      },
      "source": [
        "# Load a random image from the images folder\n",
        "file_names = next(os.walk(IMAGE_DIR))[2]\n",
        "image = skimage.io.imread(os.path.join(IMAGE_DIR, 'sh_expo.jpg'))\n",
        "\n",
        "# Run detection\n",
        "results = model.detect([image], verbose=1)\n",
        "\n",
        "# Visualize results\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6IPpQ5R2R-e",
        "colab_type": "text"
      },
      "source": [
        "## Process Video\n",
        "Download the video mp4 file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSxgxJGyGBuf",
        "colab_type": "code",
        "outputId": "9de3007a-d9f5-4194-8f64-51d7c516456b",
        "colab": {}
      },
      "source": [
        "!mkdir videos\n",
        "!wget https://github.com/Tony607/blog_statics/releases/download/v1.0/trailer1.mp4 -P ./videos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrYJWnZpr2Pm",
        "colab_type": "code",
        "outputId": "e66439bd-7954-434d-9d7e-ae3a97343d58",
        "colab": {}
      },
      "source": [
        "!ls ./videos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0o6sUx0sD3S",
        "colab_type": "code",
        "outputId": "c8f6a690-0d08-4e48-cc5d-2a7e081ccd1c",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def random_colors(N):\n",
        "    np.random.seed(1)\n",
        "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
        "    return colors\n",
        "\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"apply mask to image\"\"\"\n",
        "    for n, c in enumerate(color):\n",
        "        image[:, :, n] = np.where(\n",
        "            mask == 1,\n",
        "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
        "            image[:, :, n]\n",
        "        )\n",
        "    return image\n",
        "\n",
        "\n",
        "def display_instances(image, boxes, masks, ids, names, scores):\n",
        "    \"\"\"\n",
        "        take the image and results and apply the mask, box, and Label\n",
        "    \"\"\"\n",
        "    n_instances = boxes.shape[0]\n",
        "    colors = random_colors(n_instances)\n",
        "\n",
        "    if not n_instances:\n",
        "        print('NO INSTANCES TO DISPLAY')\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
        "\n",
        "    for i, color in enumerate(colors):\n",
        "        if not np.any(boxes[i]):\n",
        "            continue\n",
        "\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "\n",
        "        image = apply_mask(image, mask, color)\n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
        "        )\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \"\"\"\n",
        "        test everything\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import sys\n",
        "    import coco\n",
        "    import utils\n",
        "    import model as modellib\n",
        "    \n",
        "    # We use a K80 GPU with 24GB memory, which can fit 3 images.\n",
        "    batch_size = 3\n",
        "\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "    VIDEO_DIR = os.path.join(ROOT_DIR, \"videos\")\n",
        "    VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"save\")\n",
        "    COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "    if not os.path.exists(COCO_MODEL_PATH):\n",
        "        utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "    class InferenceConfig(coco.CocoConfig):\n",
        "        GPU_COUNT = 1\n",
        "        IMAGES_PER_GPU = batch_size\n",
        "\n",
        "    config = InferenceConfig()\n",
        "    config.display()\n",
        "\n",
        "    model = modellib.MaskRCNN(\n",
        "        mode=\"inference\", model_dir=MODEL_DIR, config=config\n",
        "    )\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "    class_names = [\n",
        "        'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "        'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "        'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "        'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "        'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "        'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "        'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "        'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "        'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "        'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "        'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "        'teddy bear', 'hair drier', 'toothbrush'\n",
        "    ]\n",
        "\n",
        "    capture = cv2.VideoCapture(os.path.join(VIDEO_DIR, 'trailer1.mp4'))\n",
        "    try:\n",
        "        if not os.path.exists(VIDEO_SAVE_DIR):\n",
        "            os.makedirs(VIDEO_SAVE_DIR)\n",
        "    except OSError:\n",
        "        print ('Error: Creating directory of data')\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "    # these 2 lines can be removed if you dont have a 1080p camera.\n",
        "    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
        "    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = capture.read()\n",
        "        # Bail out when the video file ends\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        # Save each frame of the video to a list\n",
        "        frame_count += 1\n",
        "        frames.append(frame)\n",
        "        print('frame_count :{0}'.format(frame_count))\n",
        "        if len(frames) == batch_size:\n",
        "            results = model.detect(frames, verbose=0)\n",
        "            print('Predicted')\n",
        "            for i, item in enumerate(zip(frames, results)):\n",
        "                frame = item[0]\n",
        "                r = item[1]\n",
        "                frame = display_instances(\n",
        "                    frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
        "                )\n",
        "                name = '{0}.jpg'.format(frame_count + i - batch_size)\n",
        "                name = os.path.join(VIDEO_SAVE_DIR, name)\n",
        "                cv2.imwrite(name, frame)\n",
        "                print('writing to file:{0}'.format(name))\n",
        "            # Clear the frames array to start the next batch\n",
        "            frames = []\n",
        "\n",
        "    capture.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKvhT2uCsIl5",
        "colab_type": "code",
        "outputId": "45533f85-556a-427f-eb22-d66a59d82c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1496
        }
      },
      "source": [
        "!ls ./videos/save"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.jpg\t 179.jpg  257.jpg  335.jpg  413.jpg  492.jpg  570.jpg  649.jpg\t727.jpg\r\n",
            "100.jpg  17.jpg   258.jpg  336.jpg  414.jpg  493.jpg  571.jpg  64.jpg\t728.jpg\r\n",
            "101.jpg  180.jpg  259.jpg  337.jpg  415.jpg  494.jpg  572.jpg  650.jpg\t729.jpg\r\n",
            "102.jpg  181.jpg  25.jpg   338.jpg  416.jpg  495.jpg  573.jpg  651.jpg\t72.jpg\r\n",
            "103.jpg  182.jpg  260.jpg  339.jpg  417.jpg  496.jpg  574.jpg  652.jpg\t730.jpg\r\n",
            "104.jpg  183.jpg  261.jpg  33.jpg   418.jpg  497.jpg  575.jpg  653.jpg\t731.jpg\r\n",
            "105.jpg  184.jpg  262.jpg  340.jpg  419.jpg  498.jpg  576.jpg  654.jpg\t732.jpg\r\n",
            "106.jpg  185.jpg  263.jpg  341.jpg  41.jpg   499.jpg  577.jpg  655.jpg\t733.jpg\r\n",
            "107.jpg  186.jpg  264.jpg  342.jpg  420.jpg  49.jpg   578.jpg  656.jpg\t734.jpg\r\n",
            "108.jpg  187.jpg  265.jpg  343.jpg  421.jpg  4.jpg    579.jpg  657.jpg\t735.jpg\r\n",
            "109.jpg  188.jpg  266.jpg  344.jpg  422.jpg  500.jpg  57.jpg   658.jpg\t736.jpg\r\n",
            "10.jpg\t 189.jpg  267.jpg  345.jpg  423.jpg  501.jpg  580.jpg  659.jpg\t737.jpg\r\n",
            "110.jpg  18.jpg   268.jpg  346.jpg  424.jpg  502.jpg  581.jpg  65.jpg\t738.jpg\r\n",
            "111.jpg  190.jpg  269.jpg  347.jpg  425.jpg  503.jpg  582.jpg  660.jpg\t739.jpg\r\n",
            "112.jpg  191.jpg  26.jpg   348.jpg  426.jpg  504.jpg  583.jpg  661.jpg\t73.jpg\r\n",
            "113.jpg  192.jpg  270.jpg  349.jpg  427.jpg  505.jpg  584.jpg  662.jpg\t740.jpg\r\n",
            "114.jpg  193.jpg  271.jpg  34.jpg   428.jpg  506.jpg  585.jpg  663.jpg\t741.jpg\r\n",
            "115.jpg  194.jpg  272.jpg  350.jpg  429.jpg  507.jpg  586.jpg  664.jpg\t742.jpg\r\n",
            "116.jpg  195.jpg  273.jpg  351.jpg  42.jpg   508.jpg  587.jpg  665.jpg\t743.jpg\r\n",
            "117.jpg  196.jpg  274.jpg  352.jpg  430.jpg  509.jpg  588.jpg  666.jpg\t744.jpg\r\n",
            "118.jpg  197.jpg  275.jpg  353.jpg  431.jpg  50.jpg   589.jpg  667.jpg\t745.jpg\r\n",
            "119.jpg  198.jpg  276.jpg  354.jpg  432.jpg  510.jpg  58.jpg   668.jpg\t746.jpg\r\n",
            "11.jpg\t 199.jpg  277.jpg  355.jpg  433.jpg  511.jpg  590.jpg  669.jpg\t747.jpg\r\n",
            "120.jpg  19.jpg   278.jpg  356.jpg  434.jpg  512.jpg  591.jpg  66.jpg\t748.jpg\r\n",
            "121.jpg  1.jpg\t  279.jpg  357.jpg  435.jpg  513.jpg  592.jpg  670.jpg\t749.jpg\r\n",
            "122.jpg  200.jpg  27.jpg   358.jpg  436.jpg  514.jpg  593.jpg  671.jpg\t74.jpg\r\n",
            "123.jpg  201.jpg  280.jpg  359.jpg  437.jpg  515.jpg  594.jpg  672.jpg\t750.jpg\r\n",
            "124.jpg  202.jpg  281.jpg  35.jpg   438.jpg  516.jpg  595.jpg  673.jpg\t751.jpg\r\n",
            "125.jpg  203.jpg  282.jpg  360.jpg  439.jpg  517.jpg  596.jpg  674.jpg\t752.jpg\r\n",
            "126.jpg  204.jpg  283.jpg  361.jpg  43.jpg   518.jpg  597.jpg  675.jpg\t753.jpg\r\n",
            "127.jpg  205.jpg  284.jpg  362.jpg  440.jpg  519.jpg  598.jpg  676.jpg\t754.jpg\r\n",
            "128.jpg  206.jpg  285.jpg  363.jpg  441.jpg  51.jpg   599.jpg  677.jpg\t755.jpg\r\n",
            "129.jpg  207.jpg  286.jpg  364.jpg  442.jpg  520.jpg  59.jpg   678.jpg\t756.jpg\r\n",
            "12.jpg\t 208.jpg  287.jpg  365.jpg  443.jpg  521.jpg  5.jpg    679.jpg\t757.jpg\r\n",
            "130.jpg  209.jpg  288.jpg  366.jpg  444.jpg  522.jpg  600.jpg  67.jpg\t758.jpg\r\n",
            "131.jpg  20.jpg   289.jpg  367.jpg  445.jpg  523.jpg  601.jpg  680.jpg\t759.jpg\r\n",
            "132.jpg  210.jpg  28.jpg   368.jpg  446.jpg  524.jpg  602.jpg  681.jpg\t75.jpg\r\n",
            "133.jpg  211.jpg  290.jpg  369.jpg  447.jpg  525.jpg  603.jpg  682.jpg\t760.jpg\r\n",
            "134.jpg  212.jpg  291.jpg  36.jpg   448.jpg  526.jpg  604.jpg  683.jpg\t761.jpg\r\n",
            "135.jpg  213.jpg  292.jpg  370.jpg  449.jpg  527.jpg  605.jpg  684.jpg\t762.jpg\r\n",
            "136.jpg  214.jpg  293.jpg  371.jpg  44.jpg   528.jpg  606.jpg  685.jpg\t763.jpg\r\n",
            "137.jpg  215.jpg  294.jpg  372.jpg  450.jpg  529.jpg  607.jpg  686.jpg\t764.jpg\r\n",
            "138.jpg  216.jpg  295.jpg  373.jpg  451.jpg  52.jpg   608.jpg  687.jpg\t765.jpg\r\n",
            "139.jpg  217.jpg  296.jpg  374.jpg  452.jpg  530.jpg  609.jpg  688.jpg\t766.jpg\r\n",
            "13.jpg\t 218.jpg  297.jpg  375.jpg  453.jpg  531.jpg  60.jpg   689.jpg\t767.jpg\r\n",
            "140.jpg  219.jpg  298.jpg  376.jpg  454.jpg  532.jpg  610.jpg  68.jpg\t768.jpg\r\n",
            "141.jpg  21.jpg   299.jpg  377.jpg  455.jpg  533.jpg  611.jpg  690.jpg\t769.jpg\r\n",
            "142.jpg  220.jpg  29.jpg   378.jpg  456.jpg  534.jpg  612.jpg  691.jpg\t76.jpg\r\n",
            "143.jpg  221.jpg  2.jpg    379.jpg  457.jpg  535.jpg  613.jpg  692.jpg\t770.jpg\r\n",
            "144.jpg  222.jpg  300.jpg  37.jpg   458.jpg  536.jpg  614.jpg  693.jpg\t771.jpg\r\n",
            "145.jpg  223.jpg  301.jpg  380.jpg  459.jpg  537.jpg  615.jpg  694.jpg\t772.jpg\r\n",
            "146.jpg  224.jpg  302.jpg  381.jpg  45.jpg   538.jpg  616.jpg  695.jpg\t773.jpg\r\n",
            "147.jpg  225.jpg  303.jpg  382.jpg  460.jpg  539.jpg  617.jpg  696.jpg\t774.jpg\r\n",
            "148.jpg  226.jpg  304.jpg  383.jpg  461.jpg  53.jpg   618.jpg  697.jpg\t775.jpg\r\n",
            "149.jpg  227.jpg  305.jpg  384.jpg  462.jpg  540.jpg  619.jpg  698.jpg\t776.jpg\r\n",
            "14.jpg\t 228.jpg  306.jpg  385.jpg  463.jpg  541.jpg  61.jpg   699.jpg\t777.jpg\r\n",
            "150.jpg  229.jpg  307.jpg  386.jpg  464.jpg  542.jpg  620.jpg  69.jpg\t778.jpg\r\n",
            "151.jpg  22.jpg   308.jpg  387.jpg  465.jpg  543.jpg  621.jpg  6.jpg\t779.jpg\r\n",
            "152.jpg  230.jpg  309.jpg  388.jpg  466.jpg  544.jpg  622.jpg  700.jpg\t77.jpg\r\n",
            "153.jpg  231.jpg  30.jpg   389.jpg  467.jpg  545.jpg  623.jpg  701.jpg\t780.jpg\r\n",
            "154.jpg  232.jpg  310.jpg  38.jpg   468.jpg  546.jpg  624.jpg  702.jpg\t781.jpg\r\n",
            "155.jpg  233.jpg  311.jpg  390.jpg  469.jpg  547.jpg  625.jpg  703.jpg\t782.jpg\r\n",
            "156.jpg  234.jpg  312.jpg  391.jpg  46.jpg   548.jpg  626.jpg  704.jpg\t78.jpg\r\n",
            "157.jpg  235.jpg  313.jpg  392.jpg  470.jpg  549.jpg  627.jpg  705.jpg\t79.jpg\r\n",
            "158.jpg  236.jpg  314.jpg  393.jpg  471.jpg  54.jpg   628.jpg  706.jpg\t7.jpg\r\n",
            "159.jpg  237.jpg  315.jpg  394.jpg  472.jpg  550.jpg  629.jpg  707.jpg\t80.jpg\r\n",
            "15.jpg\t 238.jpg  316.jpg  395.jpg  473.jpg  551.jpg  62.jpg   708.jpg\t81.jpg\r\n",
            "160.jpg  239.jpg  317.jpg  396.jpg  474.jpg  552.jpg  630.jpg  709.jpg\t82.jpg\r\n",
            "161.jpg  23.jpg   318.jpg  397.jpg  475.jpg  553.jpg  631.jpg  70.jpg\t83.jpg\r\n",
            "162.jpg  240.jpg  319.jpg  398.jpg  476.jpg  554.jpg  632.jpg  710.jpg\t84.jpg\r\n",
            "163.jpg  241.jpg  31.jpg   399.jpg  477.jpg  555.jpg  633.jpg  711.jpg\t85.jpg\r\n",
            "164.jpg  242.jpg  320.jpg  39.jpg   478.jpg  556.jpg  634.jpg  712.jpg\t86.jpg\r\n",
            "165.jpg  243.jpg  321.jpg  3.jpg    479.jpg  557.jpg  635.jpg  713.jpg\t87.jpg\r\n",
            "166.jpg  244.jpg  322.jpg  400.jpg  47.jpg   558.jpg  636.jpg  714.jpg\t88.jpg\r\n",
            "167.jpg  245.jpg  323.jpg  401.jpg  480.jpg  559.jpg  637.jpg  715.jpg\t89.jpg\r\n",
            "168.jpg  246.jpg  324.jpg  402.jpg  481.jpg  55.jpg   638.jpg  716.jpg\t8.jpg\r\n",
            "169.jpg  247.jpg  325.jpg  403.jpg  482.jpg  560.jpg  639.jpg  717.jpg\t90.jpg\r\n",
            "16.jpg\t 248.jpg  326.jpg  404.jpg  483.jpg  561.jpg  63.jpg   718.jpg\t91.jpg\r\n",
            "170.jpg  249.jpg  327.jpg  405.jpg  484.jpg  562.jpg  640.jpg  719.jpg\t92.jpg\r\n",
            "171.jpg  24.jpg   328.jpg  406.jpg  485.jpg  563.jpg  641.jpg  71.jpg\t93.jpg\r\n",
            "172.jpg  250.jpg  329.jpg  407.jpg  486.jpg  564.jpg  642.jpg  720.jpg\t94.jpg\r\n",
            "173.jpg  251.jpg  32.jpg   408.jpg  487.jpg  565.jpg  643.jpg  721.jpg\t95.jpg\r\n",
            "174.jpg  252.jpg  330.jpg  409.jpg  488.jpg  566.jpg  644.jpg  722.jpg\t96.jpg\r\n",
            "175.jpg  253.jpg  331.jpg  40.jpg   489.jpg  567.jpg  645.jpg  723.jpg\t97.jpg\r\n",
            "176.jpg  254.jpg  332.jpg  410.jpg  48.jpg   568.jpg  646.jpg  724.jpg\t98.jpg\r\n",
            "177.jpg  255.jpg  333.jpg  411.jpg  490.jpg  569.jpg  647.jpg  725.jpg\t99.jpg\r\n",
            "178.jpg  256.jpg  334.jpg  412.jpg  491.jpg  56.jpg   648.jpg  726.jpg\t9.jpg\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWDC3g8OARuc",
        "colab_type": "code",
        "outputId": "7fc1c66a-7748-4d2e-e82f-4e026fc1168b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "video = cv2.VideoCapture(os.path.join(VIDEO_DIR, 'trailer1.mp4'));\n",
        "\n",
        "# Find OpenCV version\n",
        "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "\n",
        "if int(major_ver)  < 3 :\n",
        "    fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
        "else :\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "\n",
        "video.release();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frames per second using video.get(cv2.CAP_PROP_FPS) : 30.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObiV83ORsg6o",
        "colab_type": "code",
        "outputId": "b47631cf-c3c8-44c4-db08-bbd17d6185ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def make_video(outvid, images=None, fps=30, size=None,\n",
        "               is_color=True, format=\"FMP4\"):\n",
        "    \"\"\"\n",
        "    Create a video from a list of images.\n",
        " \n",
        "    @param      outvid      output video\n",
        "    @param      images      list of images to use in the video\n",
        "    @param      fps         frame per second\n",
        "    @param      size        size of each frame\n",
        "    @param      is_color    color\n",
        "    @param      format      see http://www.fourcc.org/codecs.php\n",
        "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
        " \n",
        "    The function relies on http://opencv-python-tutroals.readthedocs.org/en/latest/.\n",
        "    By default, the video will have the size of the first image.\n",
        "    It will resize every image to this size before adding them to the video.\n",
        "    \"\"\"\n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    vid = None\n",
        "    for image in images:\n",
        "        if not os.path.exists(image):\n",
        "            raise FileNotFoundError(image)\n",
        "        img = imread(image)\n",
        "        if vid is None:\n",
        "            if size is None:\n",
        "                size = img.shape[1], img.shape[0]\n",
        "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
        "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "            img = resize(img, size)\n",
        "        vid.write(img)\n",
        "    vid.release()\n",
        "    return vid\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Directory of images to run detection on\n",
        "ROOT_DIR = os.getcwd()\n",
        "VIDEO_DIR = os.path.join(ROOT_DIR, \"videos\")\n",
        "VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"save\")\n",
        "images = list(glob.iglob(os.path.join(VIDEO_SAVE_DIR, '*.*')))\n",
        "# Sort the images by integer index\n",
        "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
        "\n",
        "outvid = os.path.join(VIDEO_DIR, \"out.mp4\")\n",
        "make_video(outvid, images, fps=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VideoWriter 0x7f7d0e7798d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1KYLXXD0YKd",
        "colab_type": "code",
        "outputId": "5773eafc-c446-4fa3-824f-dd1a33c2b051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!ls -alh ./videos/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 64M\r\n",
            "drwxr-xr-x 3 root root 4.0K Mar 25 11:00 .\r\n",
            "drwxr-xr-x 8 root root 4.0K Mar 25 10:23 ..\r\n",
            "-rw-r--r-- 1 root root  44M Mar 25 11:00 out.mp4\r\n",
            "drwxr-xr-x 2 root root  20K Mar 25 10:58 save\r\n",
            "-rw-r--r-- 1 root root  20M Mar 25 10:23 trailer1.mp4\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6vgRRXH0hwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD-3Z88I6lng",
        "colab_type": "text"
      },
      "source": [
        "### Downlod the output video to our local machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScC6ZUJq1Pc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('videos/out.mp4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7kJVPEl5NYO",
        "colab_type": "code",
        "outputId": "5e64939f-6daa-40bf-9799-4fdb169512a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assets\t    inspect_data.ipynb\t   model.py\t      shapes.py\r\n",
            "coco.py     inspect_model.ipynb    parallel_model.py  train_shapes.ipynb\r\n",
            "config.py   inspect_weights.ipynb  __pycache__\t      utils.py\r\n",
            "demo.ipynb  LICENSE\t\t   README.md\t      videos\r\n",
            "images\t    mask_rcnn_coco.h5\t   samples\t      visualize.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZNNEa_SuoFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}